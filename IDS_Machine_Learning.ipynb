{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3282df",
   "metadata": {},
   "source": [
    "CS446 FINAL PROJECT - Machine Learning in Intrusion Detection Systems (IDS)\n",
    "\n",
    "This project focuses on reproducing key findings from the study “Intrusion Detection Using Machine Learning: A Comparison Study” (Biswas, 2018), which analyzes how different feature selection methods and classifiers impact detection performance. By re-implementing and evaluating selected techniques, this project explores how machine learning can enhance intrusion detection.\n",
    "\n",
    "Author(s) : Jophene Campbell and Sophia Sasko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad53135",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Author(s): Jophene Campbell and Sophia Sasko\n",
    "\n",
    "# Importing all the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing + feature selection\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n",
    "\n",
    "sns.set()\n",
    "RANDOM_STATE = 42   # Ensures reproducibility\n",
    "TOP_K = 30          # Number of top features to keep after ranking\n",
    "CV_FOLDS = 5        # Number of cross-validation folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa0ada",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Sophia Sasko\n",
    "\"\"\"\n",
    "    Loads the NSL-KDD train and test files using the correct whitespace delimiter.\n",
    "    NSL-KDD is NOT comma-separated — it uses variable-length whitespace.\n",
    "\"\"\"\n",
    "\n",
    "def load_nsl_kdd(path=\"./Dataset\", train=\"KDDTrain+.txt\", test=\"KDDTest+.txt\"):\n",
    "    train_path = os.path.join(path, train)\n",
    "    test_path = os.path.join(path, test)\n",
    "\n",
    "    # Read 5000 rows from each file since we're limiting to 10000 rows per research paper\n",
    "    df_train = pd.read_csv(train_path, header=None, nrows=5000)\n",
    "    df_test  = pd.read_csv(test_path,  header=None, nrows=5000)\n",
    "\n",
    "    # Put two files together\n",
    "    df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "    # Remove the difficulty column\n",
    "    df = df.iloc[:, :-1]\n",
    "\n",
    "    # Rename our columns to show 42 features and the 1 label\n",
    "    df.columns = [*(f\"f{i}\" for i in range(df.shape[1]-1)), \"label\"]\n",
    "\n",
    "    print(\"Loaded data:\", df.shape)\n",
    "    return df\n",
    "\n",
    "df = load_nsl_kdd()\n",
    "with pd.option_context('display.max_rows', 20,\n",
    "                       'display.max_columns', 10,\n",
    "                       ):\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedda77b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell and Sophia Sasko\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Preprocess the NSL-KDD dataset:\n",
    "    - Clean and normalize the label column\n",
    "    - Encode categorical features (protocol_type, service, flag)\n",
    "    - Scale numerical features\n",
    "    - Return X (features) and y (labels) in machine-learning-ready form\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a safe copy so we don't modify the original DataFrame\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert the label to lowercase string and classify:\n",
    "    # If the label contains the word \"normal\", mark it as normal\n",
    "    # Otherwise, treat it as an attack\n",
    "    df[\"label\"] = df[\"label\"].apply(\n",
    "        lambda x: \"normal\" if str(x).lower() == \"normal\" else \"attack\"\n",
    "    )\n",
    "\n",
    "    X = df.drop(columns=[\"label\"])   # all input features\n",
    "    y = df[\"label\"]                  # target label\n",
    "\n",
    "\n",
    "    # NSL-KDD contains 3 symbolic/categorical columns:\n",
    "    #   - protocol_type\n",
    "    #   - service\n",
    "    #   - flag\n",
    "    # For each column that is not numeric, convert text → integer codes\n",
    "    for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "        X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "    y = LabelEncoder().fit_transform(y) #encode labels\n",
    "\n",
    "    # Standardization is critical for:\n",
    "    #   - kNN (distance-based)\n",
    "    #   - SVM (kernel-based)\n",
    "    #   - Gradient methods\n",
    "    # Converts each feature to zero-mean and unit-variance.\n",
    "    X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "    print(\"Preprocessing complete.\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "\n",
    "    return X, y #return features and labels\n",
    "\n",
    "\n",
    "# Run the preprocessing\n",
    "X, y = preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a76b40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell\n",
    "\"\"\"\n",
    "    Compute Information Gain Ratio (IGR) for each feature.\n",
    "    Higher IGR = more informative feature.\n",
    "\"\"\"\n",
    "def igr_ranking(X, y):\n",
    "    # mutual_info gives raw information gain values\n",
    "    mi = mutual_info_classif(X.values, y, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Normalize into IGR (relative to total entropy)\n",
    "    igr = mi / (mi.sum() + 1e-9)\n",
    "    out = pd.Series(igr, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    return out # Return sorted feature ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2bd50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell\n",
    "\"\"\"\n",
    "    Approximate Correlation-Based Feature Selection (CFS):\n",
    "    - High mutual information with class label\n",
    "    - Low correlation with other features (avoids redundancy)\n",
    "\"\"\"\n",
    "def cfs_ranking(X, y):\n",
    "    mi = mutual_info_classif(X.values, y)  # relevance\n",
    "    corr = X.corr().abs()                  # redundancy\n",
    "    np.fill_diagonal(corr.values, 0)       #ignore self-correlation\n",
    "\n",
    "    # CFS score = relevance / redundancy\n",
    "    redundancy = corr.mean(axis=1) + 1e-9\n",
    "    scores = mi / redundancy\n",
    "    out = pd.Series(scores, index=X.columns).sort_values(ascending=False)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65287c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell\n",
    "# Calculate IGR and CFS scores\n",
    "igr_scores = igr_ranking(X, y)\n",
    "cfs_scores = cfs_ranking(X, y)\n",
    "\n",
    "# Select top-k features for each ranking method\n",
    "top_igr = igr_scores.head(TOP_K).index.tolist()\n",
    "top_cfs = cfs_scores.head(TOP_K).index.tolist()\n",
    "\n",
    "print(\"Top IGR features:\", top_igr)\n",
    "print(\"Top CFS features:\", top_cfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98bc45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell and Sophia Sasko\n",
    "\"\"\"\n",
    "    Evaluate multiple classifiers over selected feature subsets\n",
    "    using Stratified K-Fold cross validation.\n",
    "\n",
    "    Models:\n",
    "      - kNN\n",
    "      - Decision Tree\n",
    "      - SVM\n",
    "\n",
    "    Metrics:\n",
    "      - Accuracy\n",
    "      - Precision\n",
    "      - Recall\n",
    "      - F1\n",
    "      - AUC\n",
    "\"\"\"\n",
    "def evaluate(X, y, feature_sets, folds=CV_FOLDS):\n",
    "\n",
    "    classifiers = {\n",
    "        \"kNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "        \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_STATE)\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    rows = []\n",
    "\n",
    "    for fs_name, features in feature_sets.items():\n",
    "        print(f\"\\nEvaluating feature set: {fs_name}\")\n",
    "        X_sub = X[features].values\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            print(f\"  Running classifier: {clf_name}\")\n",
    "\n",
    "            accs=[]; precs=[]; recs=[]; f1s=[]; aucs=[]\n",
    "\n",
    "            #Cross Validation Loop\n",
    "            for tr, te in skf.split(X_sub, y):\n",
    "\n",
    "                # Skip folds that collapse into one class\n",
    "                if len(np.unique(y[tr])) < 2 or len(np.unique(y[te])) < 2:\n",
    "                    continue\n",
    "\n",
    "                model = clone(clf)\n",
    "                model.fit(X_sub[tr], y[tr])\n",
    "                pred = model.predict(X_sub[te])\n",
    "\n",
    "                #Standard Metrics\n",
    "                accs.append(accuracy_score(y[te], pred))\n",
    "                precs.append(precision_score(y[te], pred, zero_division=0))\n",
    "                recs.append(recall_score(y[te], pred, zero_division=0))\n",
    "                f1s.append(f1_score(y[te], pred, zero_division=0))\n",
    "\n",
    "                # Probability-based metric (AUC)\n",
    "                try:\n",
    "                    probs = model.predict_proba(X_sub[te])\n",
    "                    if probs.shape[1] == 2:\n",
    "                        aucs.append(roc_auc_score(y[te], probs[:,1]))\n",
    "                    else:\n",
    "                        aucs.append(np.nan)\n",
    "                except:\n",
    "                    aucs.append(np.nan)\n",
    "\n",
    "            # Save averages across folds\n",
    "            rows.append({\n",
    "                \"feature_set\": fs_name,\n",
    "                \"classifier\": clf_name,\n",
    "                \"accuracy\": np.mean(accs),\n",
    "                \"precision\": np.mean(precs),\n",
    "                \"recall\": np.mean(recs),\n",
    "                \"f1\": np.mean(f1s),\n",
    "                \"auc\": np.nanmean(aucs)\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results = pd.DataFrame(rows)\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "results = evaluate(X, y, {\"IGR\": top_igr, \"CFS\": top_cfs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c0dcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Jophene Campbell and Sophia Sasko\n",
    "\n",
    "# Heatmap comparing accuracy of each classifier + feature selection method\n",
    "plt.figure(figsize=(6,4))\n",
    "pivot = results.pivot(index=\"classifier\", columns=\"feature_set\", values=\"accuracy\")\n",
    "sns.heatmap(pivot, annot=True, cmap=\"viridis\", fmt=\".3f\")\n",
    "plt.title(\"Accuracy by Classifier and Feature Selection\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc00ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Author(s): Sophia Sasko\n",
    "\"\"\"\n",
    "    Plots the top-20 feature selection scores for visualization.\n",
    "\"\"\"\n",
    "def plot_top(series, title, x_label, y_label):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(x=series.values[:20], y=series.index[:20])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()\n",
    "\n",
    "plot_top(igr_scores, \"Top IGR Features (Scores)\", \"Score\", \"IGR Features\")\n",
    "plot_top(cfs_scores, \"Top CFS Features (Scores)\", \"Score\", \"CFS Features\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
